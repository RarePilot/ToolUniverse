import os
import requests
from pathlib import Path
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import xml.etree.ElementTree as ET

class OrphadataDownloader:
    def __init__(self, base_folder='orphadata', max_workers=5):
        self.base_folder = base_folder
        self.max_workers = max_workers
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # å®šä¹‰æ‰€æœ‰ä¸‹è½½ä»»åŠ¡ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        self.downloads = [
            # Rare diseases and alignment
            {
                'url': 'https://www.orphadata.com/data/xml/en_product1.xml',
                'folder': 'Rare diseases and alignment',
                'filename': 'en_product1.xml'
            },
            {
                'url': 'https://www.orphadata.com/data/xml/zh_product1.xml',
                'folder': 'Rare diseases and alignment',
                'filename': 'zh_product1.xml'
            },
            {
                'url': 'https://www.orphadata.com/data/json/en_product1.json.tar.gz',
                'folder': 'Rare diseases and alignment',
                'filename': 'en_product1.json.tar.gz'
            },
            {
                'url': 'https://www.orphadata.com/data/json/zh_product1.json.tar.gz',
                'folder': 'Rare diseases and alignment',
                'filename': 'zh_product1.json.tar.gz'
            },
            # Linearisation of Rare Diseases
            {
                'url': 'https://www.orphadata.com/data/xml/en_product7.xml',
                'folder': 'Linearisation of Rare Diseases',
                'filename': 'en_product7.xml'
            },
            # Genes Associated with Rare Diseases
            {
                'url': 'https://www.orphadata.com/data/xml/en_product6.xml',
                'folder': 'Genes Associated with Rare Diseases',
                'filename': 'en_product6.xml'
            },
            # Phenotypes Associated with Rare Disorders
            {
                'url': 'https://www.orphadata.com/data/xml/en_product4.xml',
                'folder': 'Phenotypes Associated with Rare Disorders',
                'filename': 'en_product4.xml'
            },
            # Rare Diseases and Functional Consequences
            {
                'url': 'https://www.orphadata.com/data/xml/en_funct_consequences.xml',
                'folder': 'Rare Diseases and Functional Consequences',
                'filename': 'en_funct_consequences.xml'
            },
            # Epidemiology of Rare Diseases
            {
                'url': 'https://www.orphadata.com/data/xml/en_product9_prev.xml',
                'folder': 'Epidemiology of Rare Diseases',
                'filename': 'en_product9_prev.xml'
            },
            # Natural History of Rare Diseases
            {
                'url': 'https://www.orphadata.com/data/xml/en_product9_ages.xml',
                'folder': 'Natural History of Rare Diseases',
                'filename': 'en_product9_ages.xml'
            },
        ]
        
        # Classifications of Rare Diseases (å­åˆ†ç±»)
        classifications = [
            ('en_product3_146.xml', 'Rare cardiac diseases'),
            ('en_product3_147.xml', 'Rare developmental anomalies during embryogenesis'),
            ('en_product3_148.xml', 'Rare cardiac malformations'),
            ('en_product3_150.xml', 'Rare inborn errors of metabolism'),
            ('en_product3_152.xml', 'Rare gastroenterological diseases'),
            ('en_product3_156.xml', 'Rare genetic diseases'),
            ('en_product3_181.xml', 'Rare neurological diseases'),
            ('en_product3_182.xml', 'Rare abdominal surgical diseases'),
            ('en_product3_183.xml', 'Rare hepatic diseases'),
            ('en_product3_184.xml', 'Rare respiratory diseases'),
            ('en_product3_185.xml', 'Rare urogenital diseases'),
            ('en_product3_186.xml', 'Rare surgical thoracic diseases'),
            ('en_product3_187.xml', 'Rare skin diseases'),
            ('en_product3_188.xml', 'Rare renal diseases'),
            ('en_product3_189.xml', 'Rare ophthalmic diseases'),
            ('en_product3_193.xml', 'Rare endocrine diseases'),
            ('en_product3_194.xml', 'Rare haematological diseases'),
            ('en_product3_195.xml', 'Rare immunological diseases'),
            ('en_product3_196.xml', 'Rare systemic and rhumatological diseases'),
            ('en_product3_197.xml', 'Rare odontological diseases'),
            ('en_product3_198.xml', 'Rare circulatory system diseases'),
            ('en_product3_199.xml', 'Rare bone diseases'),
            ('en_product3_200.xml', 'Rare otorhinolaryngological diseases'),
            ('en_product3_201.xml', 'Rare infertility'),
            ('en_product3_202.xml', 'Rare neoplastic diseases'),
            ('en_product3_203.xml', 'Rare infectious diseases'),
            ('en_product3_204.xml', 'Rare diseases due to toxic effects'),
            ('en_product3_205.xml', 'Rare gynaecological and obstetric diseases'),
            ('en_product3_209.xml', 'Rare surgical maxillo-facial diseases'),
            ('en_product3_212.xml', 'Rare allergic disease'),
            ('en_product3_216.xml', 'Rare teratologic disorders'),
            ('en_product3_231.xml', 'Rare systemic and rheumatological diseases of childhood'),
            ('en_product3_233.xml', 'Rare transplant-related diseases'),
            ('en_product3_235.xml', 'Rare disorder without a determined diagnosis after full investigation'),
        ]
        
        for filename, subfolder in classifications:
            self.downloads.append({
                'url': f'https://www.orphadata.com/data/xml/{filename}',
                'folder': f'Classifications of Rare Diseases/{subfolder}',
                'filename': filename
            })
    
    def get_full_path(self, relative_folder):
        """è·å–å®Œæ•´è·¯å¾„ï¼ˆåŸºç¡€æ–‡ä»¶å¤¹ + ç›¸å¯¹è·¯å¾„ï¼‰"""
        return os.path.join(self.base_folder, relative_folder)
    
    def create_folders(self):
        """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„æ–‡ä»¶å¤¹"""
        print("\n=== åˆ›å»ºæ–‡ä»¶å¤¹ç»“æ„ ===")
        print(f"åŸºç¡€æ–‡ä»¶å¤¹: {self.base_folder}\n")
        
        # åˆ›å»ºåŸºç¡€æ–‡ä»¶å¤¹
        Path(self.base_folder).mkdir(parents=True, exist_ok=True)
        
        folders = set([self.get_full_path(item['folder']) for item in self.downloads])
        for folder in sorted(folders):
            Path(folder).mkdir(parents=True, exist_ok=True)
            # æ˜¾ç¤ºç›¸å¯¹äºåŸºç¡€æ–‡ä»¶å¤¹çš„è·¯å¾„
            relative_path = os.path.relpath(folder, self.base_folder)
            print(f"âœ“ {self.base_folder}/{relative_path}")
        
        print(f"\næ€»å…±åˆ›å»º/æ£€æŸ¥äº† {len(folders)} ä¸ªå­æ–‡ä»¶å¤¹\n")
    
    def check_file_exists(self, filepath):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°å¤§äº0"""
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            if size > 0:
                return True, size
        return False, 0
    
    def validate_file(self, filepath, filename):
        """éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            size = os.path.getsize(filepath)
            
            # æ–‡ä»¶å¤ªå°è‚¯å®šæœ‰é—®é¢˜
            if size < 100:
                return False, "æ–‡ä»¶è¿‡å°"
            
            # éªŒè¯ XML æ–‡ä»¶
            if filename.endswith('.xml'):
                try:
                    tree = ET.parse(filepath)
                    root = tree.getroot()
                    # XML æ–‡ä»¶è‡³å°‘è¦æœ‰æ ¹å…ƒç´ 
                    if root is None:
                        return False, "XML æ–‡ä»¶æ— æ•ˆ"
                except ET.ParseError as e:
                    return False, f"XML è§£æé”™è¯¯: {str(e)}"
            
            # éªŒè¯ tar.gz æ–‡ä»¶ï¼ˆæ£€æŸ¥æ–‡ä»¶å¤´ï¼‰
            elif filename.endswith('.tar.gz'):
                with open(filepath, 'rb') as f:
                    # tar.gz æ–‡ä»¶åº”è¯¥ä»¥ 0x1f 0x8b å¼€å¤´ï¼ˆgzip magic numberï¼‰
                    header = f.read(2)
                    if header != b'\x1f\x8b':
                        return False, "ä¸æ˜¯æœ‰æ•ˆçš„ gzip æ–‡ä»¶"
            
            return True, "æœ‰æ•ˆ"
            
        except Exception as e:
            return False, str(e)
    
    def download_file(self, task):
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        url = task['url']
        folder = task['folder']
        filename = task['filename']
        full_folder = self.get_full_path(folder)
        filepath = os.path.join(full_folder, filename)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ä¸”æœ‰æ•ˆ
        exists, existing_size = self.check_file_exists(filepath)
        if exists:
            is_valid, msg = self.validate_file(filepath, filename)
            if is_valid:
                return {
                    'status': 'skipped',
                    'url': url,
                    'filepath': filepath,
                    'size': existing_size,
                    'filename': filename,
                    'folder': folder
                }
            else:
                # æ–‡ä»¶å­˜åœ¨ä½†æ— æ•ˆï¼Œåˆ é™¤åé‡æ–°ä¸‹è½½
                print(f"âš  æ–‡ä»¶å·²å­˜åœ¨ä½†æ— æ•ˆï¼Œé‡æ–°ä¸‹è½½: {filename} ({msg})")
                try:
                    os.remove(filepath)
                except:
                    pass
        
        try:
            # å‘é€è¯·æ±‚
            response = self.session.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å¤§å°
            total_size = int(response.headers.get('content-length', 0))
            
            # ä¸‹è½½æ–‡ä»¶
            downloaded_size = 0
            with open(filepath, 'wb') as f, tqdm(
                desc=filename[:50],
                total=total_size if total_size > 0 else None,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
                leave=False
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
                        pbar.update(len(chunk))
            
            # è·å–å®é™…æ–‡ä»¶å¤§å°
            final_size = os.path.getsize(filepath)
            
            # éªŒè¯æ–‡ä»¶æœ‰æ•ˆæ€§ï¼ˆæ¯”å¤§å°æ£€æŸ¥æ›´å¯é ï¼‰
            is_valid, msg = self.validate_file(filepath, filename)
            if not is_valid:
                os.remove(filepath)
                return {
                    'status': 'error',
                    'url': url,
                    'filepath': filepath,
                    'filename': filename,
                    'folder': folder,
                    'error': f'æ–‡ä»¶éªŒè¯å¤±è´¥: {msg}'
                }
            
            # å¦‚æœå£°æ˜äº†å¤§å°ï¼Œä½†å®é™…å¤§å°å·®å¼‚å¾ˆå¤§ï¼ˆå°äºé¢„æœŸçš„50%ï¼‰ï¼Œå¯èƒ½æœ‰é—®é¢˜
            if total_size > 0 and final_size < total_size * 0.5:
                return {
                    'status': 'error',
                    'url': url,
                    'filepath': filepath,
                    'filename': filename,
                    'folder': folder,
                    'error': f'æ–‡ä»¶å¯èƒ½ä¸å®Œæ•´: é¢„æœŸçº¦ {total_size} å­—èŠ‚, å®é™… {final_size} å­—èŠ‚',
                    'size': final_size
                }
            
            return {
                'status': 'success',
                'url': url,
                'filepath': filepath,
                'size': final_size,
                'filename': filename,
                'folder': folder,
                'declared_size': total_size
            }
            
        except Exception as e:
            # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤å¯èƒ½ä¸å®Œæ•´çš„æ–‡ä»¶
            if os.path.exists(filepath):
                try:
                    os.remove(filepath)
                except:
                    pass
            
            return {
                'status': 'error',
                'url': url,
                'filepath': filepath,
                'error': str(e),
                'filename': filename,
                'folder': folder
            }
    
    def download_all(self):
        """å¤šçº¿ç¨‹ä¸‹è½½æ‰€æœ‰æ–‡ä»¶"""
        print(f"=== å¼€å§‹ä¸‹è½½ ===")
        print(f"æ€»æ–‡ä»¶æ•°: {len(self.downloads)}")
        print(f"çº¿ç¨‹æ•°: {self.max_workers}\n")
        
        results = {
            'success': [],
            'skipped': [],
            'error': []
        }
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self.download_file, task): task 
                for task in self.downloads
            }
            
            # ä½¿ç”¨tqdmæ˜¾ç¤ºæ€»ä½“è¿›åº¦
            with tqdm(total=len(self.downloads), desc="æ€»ä½“è¿›åº¦", unit="æ–‡ä»¶") as pbar:
                for future in as_completed(future_to_task):
                    try:
                        result = future.result()
                        results[result['status']].append(result)
                        
                        # æ‰“å°æ¯ä¸ªæ–‡ä»¶çš„çŠ¶æ€
                        if result['status'] == 'success':
                            size_mb = result['size'] / (1024 * 1024)
                            declared = result.get('declared_size', 0)
                            if declared > 0 and abs(declared - result['size']) > 1000:
                                print(f"âœ“ ä¸‹è½½æˆåŠŸ: {result['filename']} ({size_mb:.2f} MB) "
                                      f"[å£°æ˜: {declared/1024:.1f}KB, å®é™…: {result['size']/1024:.1f}KB]")
                            else:
                                print(f"âœ“ ä¸‹è½½æˆåŠŸ: {result['filename']} ({size_mb:.2f} MB)")
                        elif result['status'] == 'skipped':
                            size_mb = result['size'] / (1024 * 1024)
                            print(f"âŠ™ å·²å­˜åœ¨: {result['filename']} ({size_mb:.2f} MB)")
                        else:
                            print(f"âœ— ä¸‹è½½å¤±è´¥: {result['filename']} - {result.get('error', 'Unknown error')}")
                    except Exception as e:
                        task = future_to_task[future]
                        print(f"âœ— å¤„ç†å¼‚å¸¸: {task['filename']} - {str(e)}")
                        results['error'].append({
                            'status': 'error',
                            'url': task['url'],
                            'filename': task['filename'],
                            'folder': task['folder'],
                            'error': str(e)
                        })
                    
                    pbar.update(1)
        
        elapsed_time = time.time() - start_time
        
        # æ‰“å°æ±‡æ€»æŠ¥å‘Š
        self.print_summary(results, elapsed_time)
        
        return results
    
    def print_summary(self, results, elapsed_time):
        """æ‰“å°ä¸‹è½½æ±‡æ€»æŠ¥å‘Š"""
        print("\n" + "="*70)
        print("=== ä¸‹è½½æ±‡æ€»æŠ¥å‘Š ===")
        print("="*70)
        
        print(f"\næ€»æ–‡ä»¶æ•°: {len(self.downloads)}")
        print(f"âœ“ æˆåŠŸä¸‹è½½: {len(results['success'])} ä¸ªæ–‡ä»¶")
        print(f"âŠ™ å·²å­˜åœ¨è·³è¿‡: {len(results['skipped'])} ä¸ªæ–‡ä»¶")
        print(f"âœ— ä¸‹è½½å¤±è´¥: {len(results['error'])} ä¸ªæ–‡ä»¶")
        print(f"\næ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        
        # è®¡ç®—æ€»ä¸‹è½½å¤§å°
        total_downloaded = sum(r.get('size', 0) for r in results['success'])
        total_existing = sum(r.get('size', 0) for r in results['skipped'])
        
        print(f"\næœ¬æ¬¡ä¸‹è½½: {total_downloaded / (1024*1024):.2f} MB")
        print(f"å·²æœ‰æ–‡ä»¶: {total_existing / (1024*1024):.2f} MB")
        print(f"æ€»è®¡: {(total_downloaded + total_existing) / (1024*1024):.2f} MB")
        
        # å¦‚æœæœ‰å¤±è´¥çš„æ–‡ä»¶ï¼Œåˆ—å‡ºè¯¦æƒ…
        if results['error']:
            print("\n" + "="*70)
            print("=== å¤±è´¥æ–‡ä»¶åˆ—è¡¨ ===")
            print("="*70)
            for i, result in enumerate(results['error'], 1):
                print(f"\n{i}. æ–‡ä»¶: {result.get('filename', 'Unknown')}")
                print(f"   URL: {result.get('url', 'Unknown')}")
                print(f"   é”™è¯¯: {result.get('error', 'Unknown error')}")
        
        # æŒ‰æ–‡ä»¶å¤¹ç»Ÿè®¡
        print("\n" + "="*70)
        print("=== æŒ‰æ–‡ä»¶å¤¹ç»Ÿè®¡ ===")
        print("="*70)
        
        folder_stats = {}
        for task in self.downloads:
            folder = task['folder']
            if folder not in folder_stats:
                folder_stats[folder] = {'total': 0, 'success': 0, 'skipped': 0, 'error': 0}
            folder_stats[folder]['total'] += 1
        
        for result_list in [results['success'], results['skipped'], results['error']]:
            for result in result_list:
                folder = result.get('folder', '')
                if folder in folder_stats:
                    folder_stats[folder][result['status']] += 1
        
        for folder, stats in sorted(folder_stats.items()):
            status = "âœ“" if stats['error'] == 0 else "âœ—"
            print(f"\n{status} {self.base_folder}/{folder}")
            print(f"   æ€»è®¡: {stats['total']} | æˆåŠŸ: {stats['success']} | "
                  f"è·³è¿‡: {stats['skipped']} | å¤±è´¥: {stats['error']}")
        
        print("\n" + "="*70)
        
        if results['error']:
            print("\nâš  æœ‰æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°è¿è¡Œè„šæœ¬ç»§ç»­ä¸‹è½½")
        else:
            print("\nâœ“ æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆï¼")
        
        print("="*70 + "\n")
    
    def verify_downloads(self):
        """éªŒè¯æ‰€æœ‰ä¸‹è½½çš„æ–‡ä»¶"""
        print("\n=== éªŒè¯ä¸‹è½½æ–‡ä»¶ ===")
        
        missing_files = []
        invalid_files = []
        valid_files = []
        
        for task in self.downloads:
            full_folder = self.get_full_path(task['folder'])
            filepath = os.path.join(full_folder, task['filename'])
            exists, size = self.check_file_exists(filepath)
            
            if not exists:
                missing_files.append(task['filename'])
            else:
                is_valid, msg = self.validate_file(filepath, task['filename'])
                if not is_valid:
                    invalid_files.append((task['filename'], msg))
                else:
                    valid_files.append((task['filename'], size))
        
        print(f"\nâœ“ æœ‰æ•ˆæ–‡ä»¶: {len(valid_files)}/{len(self.downloads)}")
        print(f"âœ— ç¼ºå¤±æ–‡ä»¶: {len(missing_files)}")
        print(f"âš  æ— æ•ˆæ–‡ä»¶: {len(invalid_files)}")
        
        if missing_files:
            print("\nç¼ºå¤±æ–‡ä»¶åˆ—è¡¨:")
            for filename in missing_files:
                print(f"  - {filename}")
        
        if invalid_files:
            print("\næ— æ•ˆæ–‡ä»¶åˆ—è¡¨:")
            for filename, msg in invalid_files:
                print(f"  - {filename}: {msg}")
        
        return len(missing_files) == 0 and len(invalid_files) == 0

def main():
    print("="*70)
    print("Orphadata æ•°æ®ä¸‹è½½å™¨")
    print("="*70)
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹ï¼ˆæ‰€æœ‰æ–‡ä»¶å°†ä¸‹è½½åˆ° orphadata æ–‡ä»¶å¤¹ä¸‹ï¼‰
    downloader = OrphadataDownloader(base_folder='orphadata', max_workers=5)
    
    # åˆ›å»ºæ–‡ä»¶å¤¹
    downloader.create_folders()
    
    # ä¸‹è½½æ‰€æœ‰æ–‡ä»¶
    results = downloader.download_all()
    
    # éªŒè¯ä¸‹è½½
    all_valid = downloader.verify_downloads()
    
    if not all_valid:
        print("\nğŸ’¡ æç¤º: é‡æ–°è¿è¡Œæ­¤è„šæœ¬å°†åªä¸‹è½½ç¼ºå¤±æˆ–å¤±è´¥çš„æ–‡ä»¶")
    else:
        print("\nğŸ‰ æ­å–œï¼æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å¹¶éªŒè¯æˆåŠŸï¼")
    
    return results

if __name__ == "__main__":
    main()